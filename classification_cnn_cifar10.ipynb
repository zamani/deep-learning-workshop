{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxSoy2vCu47z"
      },
      "source": [
        "# Deep Neural Learning: CIFAR10 Classification with CNN \n",
        "\n",
        "## Mohammad Ali Zamani\n",
        "### Senior Machine Learning Scientist\n",
        " [zamani.ai](https://zamani.ai)\n",
        "\n",
        " \n",
        "some parts taken from: https://pytorch.org/tutorials/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2aUaANI0b8S"
      },
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBpB60-rUy4K"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import gzip\n",
        "from torch.utils.data import Dataset \n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yxJMH_XljXQ",
        "outputId": "d69ad159-fede-4ca9-842f-eec6a2434712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 8, 3, 1, 1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3, 1, 1)\n",
        "        self.conv3 = nn.Conv2d(16, 32, 3, 1, 1 )\n",
        "        self.conv4 = nn.Conv2d(32, 64, 3, 1, 1)\n",
        "        self.fc1 = nn.Linear(256, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <bound method _ConnectionBase.__del__ of <multiprocessing.connection.Connection object at 0x7f7251fa65c0>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 132, in __del__\n",
            "    self._close()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 361, in _close\n",
            "    _close(self._handle)\n",
            "OSError: [Errno 9] Bad file descriptor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_7Ljz8blwna"
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "class Optimization():\n",
        "    def __init__(self, args, loss,  train_loader, val_loader, test_loader):\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        device = args.device\n",
        "        self.args = args\n",
        "\n",
        "        self.model = CNN(args).to(device)\n",
        "        \n",
        "        print(\"number of trainable parameter = \", count_parameters(self.model))\n",
        "        \n",
        "        if args.optimizer == 'Adam':\n",
        "            self.optimizer = optim.Adam(self.model.parameters(), lr=args.rate)\n",
        "        elif args.optimizer == 'SGD':\n",
        "            self.optimizer = torch.optim.SGD(self.model.parameters(), lr=args.rate, momentum=args.sgd_momentum)\n",
        "\n",
        "        self.scheduler = StepLR(self.optimizer, step_size=args.lr_decay_step)\n",
        "\n",
        "        self.loss = loss\n",
        "        self.device = device\n",
        "\n",
        "    def train(self):\n",
        "        batch_counter = 0.0\n",
        "        total_loss = 0.0\n",
        "        self.model.train()\n",
        "        for iter, data in enumerate(self.train_loader, 0):\n",
        "            \n",
        "            inputs, labels = data \n",
        "\n",
        "            # To limit the number of training\n",
        "            if iter * inputs.shape[0] > self.args.sample_num:\n",
        "                break\n",
        "\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            self.model.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "\n",
        "            loss = self.loss(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            batch_counter += 1\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "        loss_value = total_loss / batch_counter\n",
        "        return loss_value\n",
        "\n",
        "    def val_eval(self):\n",
        "        batch_counter = 0.0\n",
        "        total_loss = 0.0\n",
        "        self.model.eval()\n",
        "        for iter, data in enumerate(self.val_loader, 0):\n",
        "            inputs, labels = data\n",
        "            \n",
        "            # select some of the test_set for validation\n",
        "            if iter * inputs.shape[0] >= 500:\n",
        "                break\n",
        "            \n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            \n",
        "            # for evaluating the network, we disable the gradient calculation with the no_grad function\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.loss(outputs, labels)\n",
        "\n",
        "            batch_counter += 1\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        loss_value = total_loss / batch_counter\n",
        "        return loss_value\n",
        "\n",
        "    def test_eval(self, graph=False):\n",
        "        total= 0.0\n",
        "        correct = 0\n",
        "        class_correct = list(0. for i in range(10))\n",
        "        class_total = list(0. for i in range(10))\n",
        "        self.model.eval()\n",
        "\n",
        "        for iter, data in enumerate(self.test_loader, 0):\n",
        "\n",
        "            inputs, labels = data\n",
        "            \n",
        "            if iter * inputs.shape[0] < 500:\n",
        "                continue\n",
        "            \n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "           \n",
        "            # for evaluating the network, we disable the gradient calculation with the no_grad function\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(inputs)\n",
        "                _ , predicted = torch.max(outputs, 1)\n",
        "                result = (predicted == labels)\n",
        "                total += labels.size(0)\n",
        "                correct += result.sum().item()\n",
        "\n",
        "                c = result.squeeze()\n",
        "                for i in range(labels.shape[0]):\n",
        "                    label = labels[i]\n",
        "                    class_correct[label] += c[i].item()\n",
        "                    class_total[label] += 1\n",
        "         \n",
        "        test_acc = correct / total\n",
        "        \n",
        "        print()\n",
        "        for i in range(10): \n",
        "            print('%s: %2d%%,' % (classes[i], 100 * class_correct[i] / class_total[i]), end =\" \")\n",
        "        print()\n",
        "       \n",
        "        return test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49PnXvz0l_E6"
      },
      "source": [
        "import copy\n",
        "def main(args, train_loader, val_loader, test_loader):\n",
        "    device = torch.device(args.device)\n",
        "    best_val_error = np.inf\n",
        "\n",
        "    if args.loss == 'NLL':\n",
        "        loss_function = nn.NLLLoss(reduction='mean')\n",
        "    elif args.loss == 'CE':\n",
        "        loss_function = nn.CrossEntropyLoss(reduction='mean')\n",
        "        nn.CrossEntropyLoss\n",
        "\n",
        "    optimization = Optimization(args, loss_function, train_loader, val_loader, test_loader)\n",
        "\n",
        "    train_loss_records = []\n",
        "    val_loss_records = []\n",
        "    test_loss_records = []\n",
        "\n",
        "    print(\"loading training, val and test set completed!\")\n",
        "    mistake_counter = 0  # mistakes counter for validation loss\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        train_loss = optimization.train()\n",
        "        train_loss_records.append(train_loss)\n",
        "        optimization.scheduler.step()\n",
        "\n",
        "        val_loss = optimization.val_eval()\n",
        "        val_loss_records.append(val_loss)\n",
        "\n",
        "        test_loss = optimization.test_eval()\n",
        "        test_loss_records.append(test_loss)\n",
        "\n",
        "        if epoch > 1:\n",
        "            if val_loss_records[-1] > val_loss_records[-2]:\n",
        "                mistake_counter += 1\n",
        "\n",
        "        if val_loss < best_val_error:\n",
        "            best_results = {\n",
        "                'epoch': epoch + 1,\n",
        "                'state_dict': copy.deepcopy(optimization.model.state_dict()),\n",
        "                'model': optimization.model,\n",
        "                'best_val_error': val_loss,\n",
        "                'best_test_error': test_loss,\n",
        "                'optimizer': copy.deepcopy(optimization.optimizer),\n",
        "                'args': args\n",
        "            }\n",
        "            best_val_error = val_loss\n",
        "        print(\n",
        "            '[Epoch: %3d/%3d] LR: %0.8f  Train loss: %.4f,    Val loss: %.4f,   Test Acc: %.4f'\n",
        "            % (epoch + 1, args.epochs, optimization.scheduler.get_lr()[0], train_loss_records[epoch], val_loss_records[epoch],\n",
        "               test_loss_records[epoch]))\n",
        "        \n",
        "        if mistake_counter >= args.tol or epoch == args.epochs - 1:\n",
        "            print('Training is terminated')\n",
        "            break\n",
        "    return test_loss, val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt0_CEYBmA67"
      },
      "source": [
        "from typing import NamedTuple\n",
        "class Args(NamedTuple):\n",
        "    rate: float  # learning rate\n",
        "    lr_decay_step: int  # learning rate decay\n",
        "    batch_size: int  # minibatch size\n",
        "    epochs: int  # maximum training epochs\n",
        "    sample_num: int  # number of sample to be loaded\n",
        "    tol: int  # tolerance for the validation error increment\n",
        "    device: str  # cuda or cpu\n",
        "    loss: str  # loss function     \n",
        "    optimizer: str # optimizer method\n",
        "    sgd_momentum: float #\n",
        "\n",
        "    dropout: float  # the probability for dropout \n",
        "    fc1: int # 1st hidden layer's units\n",
        "    # TODO: add more layers if necessary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91uXsoV5mC0D",
        "outputId": "6c137a40-ac7d-4014-e2e3-722a94e0b71c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(5),\n",
        "        transforms.ColorJitter(\n",
        "            brightness=0.1,\n",
        "            contrast=0.1,\n",
        "            saturation=0.1,\n",
        "            hue=0.1),\n",
        "        transforms.RandomCrop((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.CenterCrop((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "args = Args(\n",
        "            rate=0.001,\n",
        "            lr_decay_step=100,\n",
        "            batch_size=32,\n",
        "            epochs=200,\n",
        "            sample_num=5000,\n",
        "            tol=5,\n",
        "            loss='CE',\n",
        "            device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "\n",
        "            optimizer='Adam',\n",
        "            sgd_momentum=0.1,\n",
        "            dropout=0.5,\n",
        "            fc1=10, # TODO : change the first layer units \n",
        "            # TODO adjust number of next hidden unit after addition\n",
        "            )\n",
        "\n",
        "training_set = CIFAR10(root = '.', train=True, download=True, transform=data_transforms['train'])\n",
        "test_set = CIFAR10(root = '.', train=False, download=True, transform=data_transforms['val'])\n",
        "\n",
        "train_loader = DataLoader(training_set, batch_size=args.batch_size, num_workers=8, shuffle=True, drop_last=False)\n",
        "val_loader = DataLoader(test_set, batch_size=args.batch_size, num_workers=8, shuffle=False, drop_last=True)\n",
        "test_loader = DataLoader(test_set, batch_size=args.batch_size, num_workers=8, shuffle=False, drop_last=False)\n",
        "\n",
        "print(\"######################################\")\n",
        "print(\"######   sample numbers: \", args.sample_num, \"#######\")\n",
        "print(\"######################################\")\n",
        "\n",
        "main(args, train_loader, val_loader, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "######################################\n",
            "######   sample numbers:  5000 #######\n",
            "######################################\n",
            "number of trainable parameter =  66330\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane: 44%, car:  7%, bird:  3%, cat:  9%, deer: 39%, dog: 14%, frog:  8%, horse: 37%, ship: 58%, truck: 49%, \n",
            "[Epoch:   1/200] LR: 0.00100000  Train loss: 2.1355,    Val loss: 1.9236,   Test Acc: 0.2727\n",
            "\n",
            "plane: 42%, car: 50%, bird:  2%, cat:  5%, deer:  6%, dog: 19%, frog: 55%, horse: 32%, ship: 69%, truck: 12%, \n",
            "[Epoch:   2/200] LR: 0.00100000  Train loss: 1.8893,    Val loss: 1.8685,   Test Acc: 0.2964\n",
            "\n",
            "plane: 62%, car: 48%, bird:  8%, cat: 12%, deer: 44%, dog: 42%, frog: 37%, horse: 37%, ship: 44%, truck: 42%, \n",
            "[Epoch:   3/200] LR: 0.00100000  Train loss: 1.7656,    Val loss: 1.6243,   Test Acc: 0.3796\n",
            "\n",
            "plane: 54%, car: 58%, bird:  6%, cat:  6%, deer: 19%, dog: 64%, frog: 44%, horse: 54%, ship: 43%, truck: 53%, \n",
            "[Epoch:   4/200] LR: 0.00100000  Train loss: 1.6770,    Val loss: 1.5364,   Test Acc: 0.4048\n",
            "\n",
            "plane: 59%, car: 71%, bird:  6%, cat: 14%, deer: 13%, dog: 33%, frog: 79%, horse: 58%, ship: 28%, truck: 39%, \n",
            "[Epoch:   5/200] LR: 0.00100000  Train loss: 1.6365,    Val loss: 1.5404,   Test Acc: 0.4076\n",
            "\n",
            "plane: 67%, car: 52%, bird: 14%, cat: 28%, deer: 28%, dog: 22%, frog: 45%, horse: 70%, ship: 39%, truck: 67%, \n",
            "[Epoch:   6/200] LR: 0.00100000  Train loss: 1.5654,    Val loss: 1.4581,   Test Acc: 0.4366\n",
            "\n",
            "plane: 66%, car: 73%, bird: 22%, cat: 17%, deer: 54%, dog: 50%, frog: 43%, horse: 42%, ship: 51%, truck: 33%, \n",
            "[Epoch:   7/200] LR: 0.00100000  Train loss: 1.5323,    Val loss: 1.4496,   Test Acc: 0.4555\n",
            "\n",
            "plane: 55%, car: 47%, bird: 21%, cat: 33%, deer: 30%, dog: 32%, frog: 67%, horse: 67%, ship: 59%, truck: 57%, \n",
            "[Epoch:   8/200] LR: 0.00100000  Train loss: 1.4737,    Val loss: 1.3880,   Test Acc: 0.4728\n",
            "\n",
            "plane: 53%, car: 54%, bird: 24%, cat: 32%, deer: 30%, dog: 44%, frog: 61%, horse: 59%, ship: 55%, truck: 75%, \n",
            "[Epoch:   9/200] LR: 0.00100000  Train loss: 1.4455,    Val loss: 1.3571,   Test Acc: 0.4915\n",
            "\n",
            "plane: 51%, car: 42%, bird: 35%, cat: 38%, deer: 30%, dog: 52%, frog: 56%, horse: 52%, ship: 73%, truck: 62%, \n",
            "[Epoch:  10/200] LR: 0.00100000  Train loss: 1.4003,    Val loss: 1.3166,   Test Acc: 0.4967\n",
            "\n",
            "plane: 47%, car: 72%, bird: 18%, cat: 41%, deer: 41%, dog: 30%, frog: 56%, horse: 66%, ship: 80%, truck: 58%, \n",
            "[Epoch:  11/200] LR: 0.00100000  Train loss: 1.3788,    Val loss: 1.2665,   Test Acc: 0.5129\n",
            "\n",
            "plane: 53%, car: 62%, bird: 52%, cat: 36%, deer: 27%, dog: 47%, frog: 51%, horse: 58%, ship: 73%, truck: 59%, \n",
            "[Epoch:  12/200] LR: 0.00100000  Train loss: 1.3704,    Val loss: 1.2397,   Test Acc: 0.5241\n",
            "\n",
            "plane: 61%, car: 75%, bird: 23%, cat: 26%, deer: 36%, dog: 46%, frog: 56%, horse: 64%, ship: 75%, truck: 61%, \n",
            "[Epoch:  13/200] LR: 0.00100000  Train loss: 1.3198,    Val loss: 1.2331,   Test Acc: 0.5295\n",
            "\n",
            "plane: 50%, car: 60%, bird: 22%, cat: 21%, deer: 42%, dog: 50%, frog: 71%, horse: 66%, ship: 70%, truck: 79%, \n",
            "[Epoch:  14/200] LR: 0.00100000  Train loss: 1.3317,    Val loss: 1.2563,   Test Acc: 0.5366\n",
            "\n",
            "plane: 61%, car: 53%, bird: 49%, cat: 38%, deer: 43%, dog: 46%, frog: 51%, horse: 54%, ship: 76%, truck: 70%, \n",
            "[Epoch:  15/200] LR: 0.00100000  Train loss: 1.2903,    Val loss: 1.1836,   Test Acc: 0.5449\n",
            "\n",
            "plane: 56%, car: 67%, bird: 31%, cat: 41%, deer: 51%, dog: 42%, frog: 47%, horse: 65%, ship: 88%, truck: 53%, \n",
            "[Epoch:  16/200] LR: 0.00100000  Train loss: 1.2459,    Val loss: 1.2043,   Test Acc: 0.5452\n",
            "\n",
            "plane: 52%, car: 52%, bird: 42%, cat: 20%, deer: 32%, dog: 52%, frog: 69%, horse: 73%, ship: 74%, truck: 79%, \n",
            "[Epoch:  17/200] LR: 0.00100000  Train loss: 1.2396,    Val loss: 1.1678,   Test Acc: 0.5499\n",
            "\n",
            "plane: 54%, car: 57%, bird: 39%, cat: 30%, deer: 41%, dog: 58%, frog: 74%, horse: 68%, ship: 65%, truck: 75%, \n",
            "[Epoch:  18/200] LR: 0.00100000  Train loss: 1.2253,    Val loss: 1.1915,   Test Acc: 0.5663\n",
            "\n",
            "plane: 67%, car: 89%, bird: 32%, cat: 27%, deer: 21%, dog: 72%, frog: 49%, horse: 47%, ship: 73%, truck: 49%, \n",
            "[Epoch:  19/200] LR: 0.00100000  Train loss: 1.1965,    Val loss: 1.2508,   Test Acc: 0.5309\n",
            "Training is terminated\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.530881112984823, 1.250752743333578)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    }
  ]
}